# ğŸ’¤ Driver Drowsiness Detection System (CNN + OpenCV + Architecture Pruning)

This project implements a real-time driver drowsiness detection system using a lightweight Convolutional Neural Network (VGG-based), Dlib's facial landmark detection, and PyTorch for classification. Utilised pruning techniques to reduce the model's size and performance in real-time.

The system captures live video from a webcam, detects the driverâ€™s face, extracts eye regions using Dlibâ€™s 68-point facial landmark predictor, and classifies the eye state (open/closed). If the eyes remain closed for too long, an audible alarm triggers.



---

## ğŸš€ Features

- Real-time face and eye detection using OpenCV Dlib  
- Eye state classification (open/closed) using a trained VGG model  
- Alarm system (using `pygame`) to alert when eyes are closed for too long  
- Robust detection loop with scoring mechanism to avoid false positives  
- Easy-to-extend modular design (`VGG.py`, `TrainingModules.py`, `DataPreprocessing.py`)  

---

## ğŸ“ Directory Structure

```
project-root/
â”œâ”€â”€ main.py                          # Main detection loop (run this file)
â”œâ”€â”€ VGG.py                           # CNN model definition (VGG-based architecture)
â”œâ”€â”€ TrainingModules.py               # Training, validation, and prediction functions
â”œâ”€â”€ DataPreprocessing.py             # Image transforms and dataset preparation
â”œâ”€â”€ DataPreview.py                   # Visualization of dataset images and metadata
â”œâ”€â”€ DlibTest.py                      # Test script using Dlib for facial landmarks
â”œâ”€â”€ Model_Evaluation.py              # Evaluation metrics and reporting
â”œâ”€â”€ PruneEvaluator.py                # Evaluate pruned models
â”œâ”€â”€ PruneTest.py                     # Testing pruned CNNs
â”œâ”€â”€ PruneTrain.py                    # Training loop for pruned CNNs
â”œâ”€â”€ PruneViewer.py                   # Visualizer for pruned architectures and stats
â”œâ”€â”€ Test.py                          # Custom test cases for quick validation
â”œâ”€â”€ Train.py                         # General training loop
â”œâ”€â”€ Util.py                         # Helper functions (utilities)
â”œâ”€â”€ Viewer.py                        # Output and performance visualization tools
â”œâ”€â”€ DDD.ipynb                        # Jupyter notebook for interactive experiments
â”œâ”€â”€ alarm.wav                        # Alarm sound played on drowsiness detection
â”œâ”€â”€ requirement.txt                  # Required Python libraries
â”œâ”€â”€ shape_predictor_68_face_landmarks.dat  # Dlib model for facial landmarks
â”œâ”€â”€ README.md                        # Project documentation and instructions
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ checkpoint/                      # Folder for saved model checkpoints and results
â”‚   â”œâ”€â”€ accuracies.pkl               # Pickled accuracy scores
â”‚   â”œâ”€â”€ sparsities.pkl               # Pickled sparsity metrics
â”‚   â”œâ”€â”€ sensitivity_scan.png         # Plot showing sensitivity scan
â”‚   â”œâ”€â”€ vgg_metrics.txt              # Metrics summary for VGG models
â”‚   â”œâ”€â”€ vgg_mrl_99.0929946899414.pth         # Saved VGG model with 99.09% accuracy
â”‚   â”œâ”€â”€ vgg_mrl_CP_98.90.txt                  # CP model metrics
â”‚   â”œâ”€â”€ vgg_mrl_CP_98.90452575683594.pth      # Saved CP model weights
â”‚   â”œâ”€â”€ vgg_mrl_fgp_99.039.txt                # FGP model metrics
â”‚   â”œâ”€â”€ vgg_mrl_fgp_99.03999328613281.pth     # Saved FGP model weights
â”‚   â””â”€â”€ output/                      # Subdirectory for generated outputs
â”‚       â””â”€â”€ (your generated plots, logs, etc.)

```

---

## ğŸ› ï¸ Requirements

- Python 3.8 or 3.9 recommended  
- PyTorch  
- OpenCV  
- torchvision  
- pygame  
- matplotlib  
- Pillow (PIL)  
- tqdm  
- torchprofile  
- scikit-learn  

### âœ… Install via pip

```bash
pip install -r requirement.txt
```

---

## ğŸ§ª Running the Project

```bash
python main.py
```

> Press `Q` to quit the webcam window.

---

## ğŸ“· How it Works

1. Webcam captures frames in real time.  
2. Haar cascades detect the face and eyes.  
3. The cropped eye region is preprocessed and passed to a CNN model.  
4. The model classifies the eye state:  
   - **Closed**: Increases `score`  
   - **Open**: Decreases `score`  
5. If `score > 20`, the alarm is triggered via `pygame`.

---

## ğŸ§  Model Details

- The CNN is a lightweight **VGG-based** model trained on eye state data.  
- It is loaded from `checkpoint/vgg.16.pth`.  
- You can retrain or replace the model by modifying `VGG.py`.

---

## ğŸ”Š Alarm System

- The `alarm.wav` is played when the driverâ€™s eyes remain closed for a defined threshold of frames (`score > 20`).  
- Sound alert uses `pygame.mixer` to notify the driver.

---

## ğŸ“Œ Notes

- Ensure the driverâ€™s eyes are clearly visible to the camera.  
- Works best under consistent lighting conditions.  
- Thresholds (`score > 20`) can be tuned for stricter or looser alert criteria.

---

## ğŸ§¾ License

This project is intended for **academic and research purposes** only.

---

## ğŸ™‹â€â™‚ï¸ Acknowledgements

- [OpenCV](https://opencv.org/) for face and eye detection  
- [PyTorch](https://pytorch.org/) and [torchvision](https://pytorch.org/vision/stable/index.html)  
- Haar cascade classifiers provided by OpenCV  
